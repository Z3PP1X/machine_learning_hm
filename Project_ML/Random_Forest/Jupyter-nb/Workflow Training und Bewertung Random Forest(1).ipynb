{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Random Tree Workflow '''\n",
    "#imports\n",
    "\n",
    "import pandas as pd #Zur Arbeit mit dem Datenrahmen\n",
    "import matplotlib.pyplot as plt #Plotten der Diagrammwerte\n",
    "from sklearn.model_selection import train_test_split # Aufteilung des Datensatzes in Trainings und Testdaten\n",
    "from sklearn.ensemble import RandomForestRegressor # RandomForest Methode \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error # Bewertungsmetriken\n",
    "from sklearn.preprocessing import LabelEncoder # Encoder für kategorische Variablen im Datenrahmen\n",
    "import math # Für mathematische Operationen\n",
    "from sklearn.linear_model import LinearRegression # Lineare Regression zum Voraussagen der Zukunftsdaten\n",
    "from sklearn.model_selection import cross_val_score # Cross Validation des Trainingsdatensatzes\n",
    "from sklearn.model_selection import KFold # Cross Validation des Trainingsdatensatzes\n",
    "\n",
    "# Systemseitige Imports\n",
    "\n",
    "import os # => Speichern der Diagramme\n",
    "import pickle # => Speichern der Modelle\n",
    "import multiprocessing # => Alle Systemressourcen auslasten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/server_dummy_path/ML-Learning/models\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetImport:\n",
    "\n",
    "    def __init__(self, data:str, target_index) -> None:\n",
    "        \n",
    "        #Initialisierung der Instanz. Direkt in der Instanzierung bereinigen wir den Datensatz\n",
    "        #und bereiten ihn mithilfe des LabelEncoders für das spätere Training vor. \n",
    "        \n",
    "        self.target_index = target_index\n",
    "        self.dataframe = None\n",
    "        self.import_data(data)\n",
    "        self.subset_value = round(pow(self.dataframe.shape[1], 0.5))\n",
    "        self.drop_column(0)\n",
    "        self.get_dataset_columns()\n",
    "        self.label_encoding(0)\t\n",
    "        self.label_encoding(1)\n",
    "        \n",
    "\n",
    "    \n",
    "    # Random Forest Rule of Thumb:\n",
    "    # Typischerweise erzielt man die optimalen Ergebnisse mit einem Random Forest, \n",
    "    # wenn die Anzahl der maximal verwendeten Features ungefähr der Quadratwurzel \n",
    "    # der insgesamt verfügbaren Features im Datensatz entspricht. \n",
    "    # Diesen Wert berechnen wir direkt im Zuge der Initialisierung der Klasse.\n",
    "    \n",
    "    def get_recommended_subset(self, subset_value):\n",
    "        self.subset_value = subset_value\n",
    "        print(f'Recommended subset size is: {subset_value}')\n",
    "        return subset_value   \n",
    "    \n",
    "    # Import des Datensatzes\n",
    "    def import_data(self, data):\n",
    "        self.dataframe = pd.read_csv(f'{data}.csv')\n",
    "        self.dataframe.dropna(inplace= True)\n",
    "        return self.dataframe\n",
    "    \n",
    "    # Um Type_Errors zu vermeiden, schreiben wir die drop() Funktion um und \n",
    "    # referenzieren auf den Index statt dem Namen\n",
    "    \n",
    "    def drop_column(self, column_index):\n",
    "         self.dataframe.drop(self.dataframe.columns[column_index], axis=1, inplace=True)\n",
    "         return self.get_dataset_columns()\n",
    "    \n",
    "    # Gibt die zur Verfügung stehenden Spalten aus\n",
    "\n",
    "    def get_dataset_columns(self):\n",
    "        columns_list = list(self.dataframe.columns)\n",
    "        print(f'Available Datapoints: {columns_list}')\n",
    "        return columns_list\n",
    "    \n",
    "    # Gibt die Datenwerte einer Spalte aus, hier wird wieder auf den Index referenziert um Type_Errors zu vermeiden.\n",
    "\n",
    "    def get_data_from_column(self, column_index: int):\n",
    "        column_data = self.dataframe[self.dataframe.columns[column_index]]\n",
    "        print(column_data)\n",
    "        return column_data\n",
    "    \n",
    "    # Der LabelEncoder kodiert kategorische Werte (bspw. Ländernamen) in numerische Werte, da der Random Forest\n",
    "    # nur mit numerischen Werten arbeiten kann. \n",
    "    \n",
    "    def label_encoding(self, column_index: int):\n",
    "        label_encoder = LabelEncoder()\n",
    "        self.dataframe[self.dataframe.columns[column_index]] = label_encoder.fit_transform(\n",
    "            self.dataframe[self.dataframe.columns[column_index]]\n",
    "        )\n",
    "        \n",
    "    # Die Funktion `generate_test_sets` teilt das Datenset in Trainings- und Testdatensätze auf. \n",
    "    # Die Aufteilung basiert auf dem angegebenen Verhältnis `test_size`.\n",
    "    # `X_train` und `y_train` sind die Trainingsdaten und -zielwerte, `X_test` und `y_test` sind die \n",
    "    # entsprechenden Testdatensätze. Die Reproduzierbarkeit der Aufteilung wird durch den optionalen\n",
    "    # Parameter `random_state` ermöglicht.\n",
    "    \n",
    "    \n",
    "    def generate_test_sets(self, test_size: float, random_state=None):\n",
    "        parameter = list(self.dataframe.drop(self.dataframe.columns[self.target_index], axis=1).columns)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        self.dataframe[parameter],\n",
    "        self.dataframe[self.dataframe.columns[self.target_index]],\n",
    "        test_size=test_size\n",
    "    )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    \n",
    "    def generate_future_data(self, end_year):\n",
    "        # Entferne alle Zeilen mit Ländercode 195 oder Energy_Type gleich 0\n",
    "        # Ländercode 195 ist Welt und der Energy_type 0 beschreibt alle Energie-Typen\n",
    "        df_filtered = self.dataframe[\n",
    "            (self.dataframe['Country'] != 195) & \n",
    "            (self.dataframe['Energy_type'] != 0)\n",
    "        ]\n",
    "\n",
    "        # Finde den niedrigsten und höchsten Ländercode\n",
    "        min_country_code = df_filtered['Country'].min()\n",
    "        max_country_code = df_filtered['Country'].max()\n",
    "\n",
    "        future_data_list = []\n",
    "\n",
    "        target_name = self.dataframe.columns[self.target_index]\n",
    "\n",
    "        # Durchlaufe alle Ländercodes im Bereich von min_country_code bis max_country_code\n",
    "        for country_code in range(min_country_code, max_country_code + 1):\n",
    "            df_country = df_filtered[df_filtered['Country'] == country_code]\n",
    "\n",
    "            start_year = df_country['Year'].max() + 1\n",
    "            future_data = pd.DataFrame({'Year': range(start_year, end_year + 1)})\n",
    "\n",
    "            # Durchlaufe alle Features außer ausgeschlossene\n",
    "            excluded_features = ['Year', 'Country', 'Energy_type', target_name]\n",
    "\n",
    "            for feature in df_country.columns:\n",
    "                if feature not in excluded_features:\n",
    "                    X = df_country[['Year']]\n",
    "                    y = df_country[feature]\n",
    "                    model = LinearRegression()\n",
    "                    model.fit(X, y)\n",
    "                    predictions = model.predict(future_data[['Year']])\n",
    "                    future_data[feature] = abs(predictions)\n",
    "\n",
    "            # Füge 'Country' und 'Energy_type' Informationen zu 'future_data' hinzu\n",
    "            future_data['Country'] = country_code\n",
    "            # Nehme den meistgenutzten Energy_type des jeweiligen Landes, der nicht 0 ist\n",
    "            future_data['Energy_type'] = df_country['Energy_type'].mode()[0]\n",
    "\n",
    "            future_data_list.append(future_data)\n",
    "\n",
    "        # Kombiniere alle DataFrames aus der Liste in ein einziges DataFrame\n",
    "        combined_future_data = pd.concat(future_data_list, ignore_index=True)\n",
    "        desired_order = ['Country', 'Energy_type', 'Year', 'Energy_consumption', 'Energy_production', 'GDP', 'Population', 'Energy_intensity_per_capita', 'Energy_intensity_by_GDP']\n",
    "        combined_future_data = combined_future_data[desired_order]\n",
    "\n",
    "        # Speichere das kombinierte DataFrame in der Klasse für zukünftige Verwendung\n",
    "        self.df_future = combined_future_data\n",
    "        return combined_future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logik für den Plot der Diagramme\n",
    "\n",
    "def plot_cv_performance(best_mse_per_estimator, start_estimators, end_estimators, chart_path, random_state):\n",
    "    plt.figure(figsize=(10, 8))  # Größe des Plots anpassen\n",
    "    plt.plot(list(best_mse_per_estimator.keys()), list(best_mse_per_estimator.values()), marker='o', color='blue', \n",
    "             label='CV MSE')\n",
    "\n",
    "    plt.xlabel('Anzahl der Estimatoren')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('CV MSE für verschiedene Anzahlen von Estimatoren')\n",
    "\n",
    "    # Finde den niedrigsten MSE-Wert sowie die entsprechende Anzahl von Estimatoren\n",
    "    min_cv_mse = min(best_mse_per_estimator.values())\n",
    "    min_cv_estimators = min(best_mse_per_estimator, key=best_mse_per_estimator.get)\n",
    "    \n",
    "    # Bestimmen der Grenze für die Y-Achse um dynamische Limits zu ermöglichen\n",
    "    ymin, ymax = plt.ylim() \n",
    "    offset = (ymax - ymin) * 0.15 #Pfeil verschieben\n",
    "    \n",
    "    # Erstelle das Textfeld und den dünnen Pfeil\n",
    "    plt.annotate(\n",
    "        f'Min CV MSE: {round(min_cv_mse, 2)}',\n",
    "        xy=(min_cv_estimators, min_cv_mse),  # Position des niedrigsten CV MSE herausfinden\n",
    "        xytext=(min_cv_estimators, min_cv_mse + offset),  # Dynamische Verschiebung oberhalb des niedrigsten Punktes\n",
    "        textcoords='data',\n",
    "        arrowprops=dict(facecolor='blue', width=0.5, headwidth=5, shrink=0.05),  # Stil des Pfeils\n",
    "        horizontalalignment='center',  # Zentriere den Text horizontal über dem Pfeil\n",
    "        verticalalignment='bottom',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", alpha=0.5, color='blue')  # Fügt dem Textfeld die Umrandung hinzu\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    #Die Bilder die folgend gespeichert werden, haben wir unten angefügt in Anhang 1\n",
    "    plt.savefig(f\"{chart_path}/cv_mse_versus_estimators{start_estimators}_{end_estimators}_rs{str(random_state)}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_test_performance(test_mse_per_estimator, best_mae, best_r2, start_estimators, end_estimators, chart_path, \n",
    "                          random_state):\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(list(test_mse_per_estimator.keys()), list(test_mse_per_estimator.values()), marker='x', linestyle='--', color='green', label='Test MSE')\n",
    "\n",
    "    plt.xlabel('Anzahl der Estimatoren')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Test MSE für verschiedene Anzahlen von Estimatoren')\n",
    "\n",
    "    # Finde den niedrigsten MSE-Wert sowie die entsprechende Anzahl von Estimatoren\n",
    "    min_test_mse = min(test_mse_per_estimator.values())\n",
    "    min_test_estimators = min(test_mse_per_estimator, key=test_mse_per_estimator.get)\n",
    "\n",
    "    # Text für MAE und R^2-Werte erstellen, die im Diagramm angezeigt werden\n",
    "    text_str = (f'Min Test MSE: {round(min_test_mse, 4)}\\n'\n",
    "                f'Best MAE: {round(best_mae, 4)}\\n'\n",
    "                f'Best R^2: {round(best_r2, 4)}\\n'\n",
    "                'Test size: 20 %')\n",
    "\n",
    "    # Positioniere den Text in der Mitte oben im Diagramm\n",
    "    plt.gca().text(0.5, 0.85, text_str, fontsize=12, ha='center', va='top', transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Zeichne die Legende, ohne dass sie die Textbox überlappt\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    ymin, ymax = plt.ylim()  # Aktuellen y-Achsenbereich abrufen\n",
    "    y_offset = (ymax - ymin) * 0.15\n",
    "\n",
    "    plt.annotate(\n",
    "        f'Min Test MSE: {round(min_test_mse, 2)}',\n",
    "        xy=(min_test_estimators, min_test_mse),  # Position des niedrigsten Test MSE\n",
    "        xytext=(min_test_estimators, min_test_mse + y_offset),  # Dynamische Verschiebung oberhalb des niedrigsten Punktes\n",
    "        textcoords='data',\n",
    "        arrowprops=dict(facecolor='black', width=0.5, headwidth=5, shrink=0.05),  # Stil des Pfeils\n",
    "        horizontalalignment='center',  # Zentriert den Text horizontal um den Pfeil\n",
    "        verticalalignment='bottom',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", alpha=0.5, color='green')\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Verhindere das Abschneiden von Titeln oder Legenden\n",
    "    plt.savefig(f\"{chart_path}/test_mse_versus_estimators{start_estimators}_{end_estimators}_rs{str(random_state)}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow:\n",
    "# Zunächst wird ein Random Forest-Modell unter Verwendung von Kreuzvalidierung (cv) trainiert, um den durchschnittlichen\n",
    "# MSE (Mean Squared Error) zu ermitteln.\n",
    "# Dann werden verschiedene Modelle mit unterschiedlicher Anzahl von Estimatoren trainiert, um den optimalen Wert zu finden.\n",
    "# Das beste Modell mit der niedrigsten Fehlerrate wird schließlich gespeichert.\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_cv(X_train, y_train, n_estimators, cv_folds, random_state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trainiert einen RandomForestRegressor mit Kreuzvalidierung und berechnet den durchschnittlichen negativen MSE.\n",
    "    \n",
    "    Parameter:\n",
    "    - X_train: Trainingsdatensatz\n",
    "    - y_train: Abhängige Variable\n",
    "    - n_estimators: Anzahl der Bäume im Random Forest\n",
    "    - cv_folds: Anzahl der Folds in der Kreuzvalidierung\n",
    "    - random_state: Seed für die Zufälligkeit um Reproduzierbarkeit zu gewährleisten\n",
    "    \n",
    "    Rückgabe:\n",
    "    - Durchschnittlicher negativer MSE über alle Kreuzvalidierungsfolds hinweg\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)    \n",
    "    clf = RandomForestRegressor(n_estimators=n_estimators, max_features=3, random_state=random_state, n_jobs=-1)    \n",
    "    mse_scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)    \n",
    "    mse_scores = -mse_scores\n",
    "\n",
    "    '''\n",
    "    Erklärung negativer MSE:\n",
    "    scikit-learn gibt den MSE bei der Kreuzvalidierung immer negativ zurück.\n",
    "    '''\n",
    "    \n",
    "    average_mse = mse_scores.mean()\n",
    "    \n",
    "    return average_mse\n",
    "\n",
    "def train_and_save_best_model(X_train, y_train, n_estimators, cv_folds=5, random_state=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Legacy Version: \n",
    "    Diese Funktion war in einer alten Codeversion wichtig, um nicht alle Variablen neu schreiben zu müssen\n",
    "    befindet sie sich weiterhin im Repository.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_mse = train_and_evaluate_cv(X_train, y_train, n_estimators, cv_folds, random_state)\n",
    "    return best_mse\n",
    "\n",
    "def find_optimal_estimators(X_train, y_train, X_test, y_test, start_estimators=25, end_estimators=400, step=25, \n",
    "                            cv_folds=10, chart_path=\"/home/server_dummy_path/ML-Learning/figures\", \n",
    "                            model_path=\"/home/server_dummy_path/ML-Learning/models\", random_state=None):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Ermittelt die optimale Anzahl von Estimatoren für den RandomForestRegressor durch Training und Evaluierung \n",
    "    von Modellen mit unterschiedlichen Estimator-Anzahlen. Die Modelle werden mittels Kreuzvalidierung bewertet \n",
    "    und zusätzlich auf einem separaten Testdatensatz getestet. Ein Modell wird nur dann gespeichert und für \n",
    "    das Plotten markiert, wenn es auf dem Testdatensatz besser abschneidet als bei der Kreuzvalidierung.\n",
    "\n",
    "    Parameter:\n",
    "    - X_train: Die zur Verfügung stehenden Trainingsdaten.\n",
    "    - y_train: Die zugehörigen Trainingszielwerte.\n",
    "    - X_test: Die zur Verfügung stehenden Testdaten.\n",
    "    - y_test: Die zugehörigen Testzielwerte.\n",
    "    - start_estimators, end_estimators, step: Definieren einen Bereich und eine Schrittgröße für die Anzahl \n",
    "      der bei den Random-Forest-Modellen zu testenden Bäume (Estimatoren).\n",
    "    - cv_folds: Die Anzahl der Durchführungen der Kreuzvalidierung.\n",
    "    - chart_path: Der Speicherpfad für Diagramme, die die Modellleistung visualisieren.\n",
    "    - model_path: Der Speicherpfad für das beste Random-Forest-Modell.\n",
    "    - random_state: Ein Seed-Wert, um reproduzierbare Ergebnisse zu gewährleisten.\n",
    "\n",
    "    Rückgabe:\n",
    "    - Ein Dictionary, das die Anzahl von Estimatoren auf den besten Kreuzvalidierungs-MSE abbildet.\n",
    "    - Ein weiteres Dictionary, das die Anzahl von Estimatoren auf den MSE des Testdatensatzes abbildet.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_mse_per_estimator = {}\n",
    "    test_mse_per_estimator = {}\n",
    "    plot_flag = False  # Hinzugefügte boolesche Variable, um zu bestimmen, ob geplottet werden soll\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_cv_mse = float('inf')\n",
    "    best_n_estimators = 0\n",
    "    best_r2 = 0\n",
    "    best_mae = float('inf')\n",
    "    \n",
    "    for n_estimators in range(start_estimators, end_estimators + 1, step):\n",
    "        print(f\"Training mit {n_estimators} Estimatoren...\")\n",
    "        cv_mse = train_and_save_best_model(X_train, y_train, n_estimators, cv_folds, random_state)\n",
    "        best_mse_per_estimator[n_estimators] = cv_mse\n",
    "\n",
    "        # Berechne den Test-MSE für das aktuelle Modell\n",
    "        test_mse, test_r2, test_mae = evaluate_on_test_data(X_train, y_train, X_test, y_test, n_estimators, random_state)\n",
    "        test_mse_per_estimator[n_estimators] = test_mse\n",
    "\n",
    "        if cv_mse < best_cv_mse: # Aktualisieren des besten CV-MSEs falls nötig\n",
    "            best_cv_mse = cv_mse\n",
    "            \n",
    "        if test_mse < cv_mse:\n",
    "            if test_mse < best_mse:  # Vergleich des Test-MSE\n",
    "                best_mse = test_mse\n",
    "                best_r2 = test_r2  # Speichern des R^2-Wertes des besten Modells\n",
    "                best_mae = test_mae  # Speichern des MAE des besten Modells\n",
    "                best_n_estimators = n_estimators\n",
    "                best_model = RandomForestRegressor(n_estimators=best_n_estimators, max_features=int(math.sqrt(X_train.shape[1])), random_state=random_state, n_jobs=-1)\n",
    "                best_model.fit(X_train, y_train)\n",
    "                plot_flag = True  # Setzen des Flags für das Plotten\n",
    "\n",
    "    # Speichern des besten Modells\n",
    "    if best_model is not None:\n",
    "        if plot_flag:\n",
    "            with open(f\"{model_path}/best_model_estimators_{best_n_estimators}_rs{str(random_state)}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(best_model, f)\n",
    "            print(f\"Das beste Modell mit {best_n_estimators} Estimatoren wurde als Pickle-Datei gespeichert.\")\n",
    "\n",
    "    # Ruft die Plot-Funktionen auf, wenn plot_flag gesetzt ist, nachdem alle Iterationen beendet wurden\n",
    "    if plot_flag:\n",
    "        plot_cv_performance(best_mse_per_estimator, start_estimators, end_estimators, chart_path, random_state)\n",
    "        plot_test_performance(test_mse_per_estimator, best_mae, best_r2, start_estimators, end_estimators, chart_path, random_state)\n",
    "\n",
    "    return best_mse_per_estimator, test_mse_per_estimator\n",
    "\n",
    "def evaluate_on_test_data(X_train, y_train, X_test, y_test, n_estimators, random_state=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trainiert einen RandomForestRegressor und bewertet ihn anhand von Testdaten.\n",
    "\n",
    "    Argumente:\n",
    "        X_train: Trainingsdatensatz.\n",
    "        y_train: Zielwerte des Trainingsdatensatzes.\n",
    "        X_test: Testdatensatz zur Evaluation.\n",
    "        y_test: Zielwerte des Testdatensatzes.\n",
    "        n_estimators: Anzahl der Entscheidungsbäume im RandomForestRegressor.\n",
    "        random_state: Parameter zur Generierung von reproduzierbaren Ergebnissen.\n",
    "\n",
    "    Gibt zurück:\n",
    "        test_mse: Mean Squared Error des Modells auf dem Testdatensatz.\n",
    "        test_r2: R-squared-Wert, der angibt, wie gut die vorhergesagten Werte mit den tatsächlichen Zielwerten übereinstimmen.\n",
    "        test_mae: Mean Absolute Error des Modells auf dem Testdatensatz.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=n_estimators, max_features=int(math.sqrt(X_train.shape[1])), random_state=random_state, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, predictions)\n",
    "    test_r2 = r2_score(y_test, predictions)\n",
    "    test_mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    return test_mse, test_r2, test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der Funktionsaufruf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = DatasetImport('energy', 9)\n",
    "    for i in range(12):\n",
    "        X_train, X_test, y_train, y_test = dataset.generate_test_sets(test_size=0.2, random_state=i)\n",
    "        optimal_estimators_mse, test_mse_per_estimator = find_optimal_estimators(X_train, y_train, X_test, y_test, start_estimators=25, end_estimators=400, step=25, cv_folds=10, random_state=i)\n",
    "        print(\"Optimal Estimators MSE:\")\n",
    "        print(optimal_estimators_mse)\n",
    "        print(\"\\nTest MSE per Estimator:\")\n",
    "        print(test_mse_per_estimator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
